# ==== Set User for local NIM deployment ====
export USERID=$(id -u)
export NVIDIA_API_KEY=${NGC_API_KEY}

# ==== Endpoints for using on-prem NIMs ====
export APP_LLM_SERVERURL=nim-llm:8000
export APP_FILTEREXPRESSIONGENERATOR_SERVERURL=nim-llm:8000
export SUMMARY_LLM_SERVERURL=nim-llm:8000
export APP_EMBEDDINGS_SERVERURL=nemoretriever-embedding-ms:8000
# For VLM Embedding Model
# export APP_EMBEDDINGS_SERVERURL=nemoretriever-vlm-embedding-ms:8000
export APP_RANKING_SERVERURL=nemoretriever-ranking-ms:8000
export OCR_GRPC_ENDPOINT=paddle:8001
export OCR_INFER_PROTOCOL=grpc
export OCR_MODEL_NAME=paddle
export OCR_HTTP_ENDPOINT=http://paddle:8000/v1/infer
export YOLOX_GRPC_ENDPOINT=page-elements:8001
export YOLOX_INFER_PROTOCOL=grpc
export YOLOX_GRAPHIC_ELEMENTS_GRPC_ENDPOINT=graphic-elements:8001
export YOLOX_GRAPHIC_ELEMENTS_INFER_PROTOCOL=grpc
export YOLOX_TABLE_STRUCTURE_GRPC_ENDPOINT=table-structure:8001
export YOLOX_TABLE_STRUCTURE_INFER_PROTOCOL=grpc

# ==== Endpoints for using cloud NIMs ===
# export APP_EMBEDDINGS_SERVERURL=""
# export APP_LLM_SERVERURL=""
# export APP_LLM_MODELNAME=nvidia/llama-3.3-nemotron-super-49b-v1.5
# export APP_FILTEREXPRESSIONGENERATOR_MODELNAME=nvidia/llama-3.3-nemotron-super-49b-v1.5
# export APP_FILTEREXPRESSIONGENERATOR_SERVERURL=""
# export SUMMARY_LLM="nvidia/llama-3.3-nemotron-super-49b-v1.5"
# export APP_RANKING_SERVERURL=""
# export SUMMARY_LLM_SERVERURL=""
# export OCR_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/baidu/paddleocr
# export OCR_INFER_PROTOCOL=http
# export OCR_MODEL_NAME=paddle
# export YOLOX_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-page-elements-v2
# export YOLOX_INFER_PROTOCOL=http
# export YOLOX_GRAPHIC_ELEMENTS_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-graphic-elements-v1
# export YOLOX_GRAPHIC_ELEMENTS_INFER_PROTOCOL=http
# export YOLOX_TABLE_STRUCTURE_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-table-structure-v1
# export YOLOX_TABLE_STRUCTURE_INFER_PROTOCOL=http
# export APP_QUERYREWRITER_SERVERURL=""
# export APP_QUERYREWRITER_MODELNAME="nvidia/llama-3.3-nemotron-super-49b-v1.5"


# Set GPU IDs for local deployment
# ==== LLM ====
export LLM_MS_GPU_ID=1

# ==== Embeddings ====
export EMBEDDING_MS_GPU_ID=0
export VLM_EMBEDDING_MS_GPU_ID=0

# ==== Reranker ====
export RANKING_MS_GPU_ID=0

# ==== Vector DB GPU ID ====
export VECTORSTORE_GPU_DEVICE_ID=0

# ==== Ingestion NIMs GPU ids ====
export YOLOX_MS_GPU_ID=0
export YOLOX_GRAPHICS_MS_GPU_ID=0
export YOLOX_TABLE_MS_GPU_ID=0
export OCR_MS_GPU_ID=0

# Set absolute path for prompts file
export PROMPT_CONFIG_FILE=${PWD}/src/nvidia_rag/rag_server/prompt.yaml