services:

  # Milvus can be made GPU accelerated by uncommenting the lines as specified below
  milvus:
    container_name: milvus-standalone
    image: milvusdb/milvus:${MILVUS_VERSION:-v2.6.0-gpu} # milvusdb/milvus:v2.6.0 for CPU
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9010
      KNOWHERE_GPU_MEM_POOL_SIZE: 2048;4096
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
    #   interval: 30s
    #   start_period: 90s
    #   timeout: 20s
    #   retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"
    # Comment out this section if CPU based image is used and set below env variables to False
    # export APP_VECTORSTORE_ENABLEGPUSEARCH=False
    # export APP_VECTORSTORE_ENABLEGPUINDEX=False
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
              # count: ${INFERENCE_GPU_COUNT:-all}
              device_ids: ['${VECTORSTORE_GPU_DEVICE_ID:-0}']
    profiles: ["", "milvus"]

  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.6.4
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    profiles: ["", "milvus"]

  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2025-07-23T15-54-02Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9011:9011"
      - "9010:9010"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    command: minio server /minio_data --console-address ":9011" --address ":9010"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9010/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    profiles: ["", "milvus", "elasticsearch", "cyborgdb", "minio"]

  elasticsearch:
    container_name: elasticsearch
    image: "docker.elastic.co/elasticsearch/elasticsearch:9.0.3"
    ports:
      - 9200:9200
    volumes:
      # Run "sudo chown -R 1000:1000 deploy/compose/volumes/elasticsearch/" to fix permissions
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/elasticsearch:/usr/share/elasticsearch/data
    restart: on-failure
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1024m -Xmx1024m"
      - xpack.security.enabled=false
      - xpack.license.self_generated.type=basic
      - network.host=0.0.0.0
      - cluster.routing.allocation.disk.threshold_enabled=false
    hostname: elasticsearch
    healthcheck:
      test: ["CMD", "curl", "-s", "-f", "http://localhost:9200/_cat/health"]
      interval: 10s
      timeout: 1s
      retries: 10
    profiles: ["elasticsearch"]

  cyborgdb:
    container_name: cyborgdb
    image: cyborginc/cyborgdb-service:latest
    ports:
      - "8000:8000"
    environment:
      - CYBORGDB_DB_TYPE=redis
      - CYBORGDB_CONNECTION_STRING=host:cyborgdb-redis,port:6379,db:0
      - CYBORGDB_API_KEY=${CYBORGDB_API_KEY:-}
      - PORT=8000
    depends_on:
      cyborgdb-redis:
        condition: service_healthy
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
      interval: 30s
      timeout: 20s
      retries: 3
    profiles: ["cyborgdb"]

  cyborgdb-redis:
    container_name: cyborgdb-redis
    image: redis:7-alpine
    ports:
      - "6380:6379"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/redis:/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    profiles: ["cyborgdb"]

networks:
  default:
    name: nvidia-rag